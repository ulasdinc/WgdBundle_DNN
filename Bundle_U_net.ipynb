{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bundle_U-net.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p45UjNjFyoHc"
      },
      "source": [
        "# U-net type encoder-decoder convolutional neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mIcpL6pLPvL"
      },
      "source": [
        "### Import required Python libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaV4mHBXVj2x"
      },
      "source": [
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Activation\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import concatenate, UpSampling2D, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import scipy.io as sio\n",
        "\n",
        "# This will prompt for authorization. This enables to load files stored in your google drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyAUlWj6Ar3F"
      },
      "source": [
        "# !pip install sklearn\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.ndimage import interpolation"
      ],
      "metadata": {
        "id": "x3IZ3RId-JET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVMwTVUOV1KY"
      },
      "source": [
        "### Import, process, and shape the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxMLelekV8xh"
      },
      "source": [
        "# load data from Google drive\n",
        "filename = '/content/drive/MyDrive/Giulia waveguides/Paper/outputs BPM/1cm/combined_normalized/output_stack_3e-5.mat' # Uploading output from BPM\n",
        "mat_contents = sio.loadmat(filename)\n",
        "NN_input = mat_contents['output_stack']\n",
        "print(\"data loaded...\")\n",
        "maxNN_input=np.max(NN_input)\n",
        "NN_input=NN_input/maxNN_input\n",
        "print(NN_input.shape)\n",
        "\n",
        "filename = '/content/drive/MyDrive/Giulia waveguides/network/dataset/d_all_norm256.mat' # Uploading the original digits\n",
        "mat_contents = sio.loadmat(filename)\n",
        "NN_originals = mat_contents['d_all_norm256']\n",
        "print(\"data loaded...\")\n",
        "\n",
        "print(NN_originals.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrCRJ1FKECO9"
      },
      "source": [
        "plt.imshow(NN_input[5, :, :], cmap='viridis')\n",
        "#plt.title('output_test [' + str(test_id) + ']')\n",
        "plt.colorbar()\n",
        "plt.grid(None)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### RUN THIS SECTION IF YOU WANT TO ADD NOISE ###\n",
        "for ii in range(1170):\n",
        "  noise=np.random.rand(5,5)\n",
        "  noise_up= interpolation.zoom(noise,256/5)\n",
        "  noise_up=noise_up/np.max(noise_up)\n",
        "  NN_input[ii,:,:]=noise_up*0.25+NN_input[ii, :, :]\n",
        "\n",
        "plt.imshow(NN_input[5, :, :], cmap='viridis')\n",
        "#plt.title('output_test [' + str(test_id) + ']')\n",
        "plt.colorbar()\n",
        "plt.grid(None)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yn3m_HmKTuhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### RUN THIS SECTION IF YOU WANT TO REMOVE THE CLADDING LIGHT  ###\n",
        "# Construct the binary mask \n",
        "Nx       = 256                                   # x-direction size of computational grid\n",
        "Ny       = Nx                                    # x-direction size of computational grid. The computation domain is square\n",
        "Lx_ = 140e-6                                     # width of the computation window [m] \n",
        "Ly_ = Lx_\t\t                                     # height of the computation window [m] \n",
        "dx_ = Lx_/Nx                                     # normalized discretization step in x\n",
        "x_  = dx_ * np.arange(-Nx/2,Nx/2,1)              # x dimension vector\n",
        "dy_ = Ly_/Ny                                       \n",
        "y_  = dy_ * np.arange(-Ny/2,Ny/2,1)                          \n",
        "[X_, Y_]    = np.meshgrid(x_, y_)\n",
        "\n",
        "wgds =np.zeros((Nx,Ny))\n",
        "width_x  = (2e-6)  *1                           \n",
        "width_y  = (2.5e-6)*1                          \n",
        "seperation = 30e-6                              # waveguide centor-to-center seperation (pitch)\n",
        "wgd_num=int(120e-6/seperation+1)\n",
        "\n",
        "for ii in range(wgd_num):\n",
        "  for jj in range(wgd_num):\n",
        "    ii_=ii-(wgd_num-1)/2\n",
        "    jj_=jj-(wgd_num-1)/2\n",
        "    wgds[np.logical_and(np.abs(X_-ii_*seperation)<=width_x/2,  np.abs(Y_-jj_*seperation)<=width_y/2)]=1 \n",
        "  \n",
        "plt.imshow((wgds),extent=[-Lx_/2*1e6,Lx_/2*1e6,-Ly_/2*1e6,Ly_/2*1e6])\n",
        "plt.colorbar()\n",
        "plt.xlabel('x axis [um]')\n",
        "plt.ylabel('y axis [um]')\n",
        "plt.show()\n",
        "\n",
        "# Remove the cladding light\n",
        "for ii in range(1170):\n",
        "  NN_input[ii,:,:]=wgds*NN_input[ii, :, :]\n",
        "\n",
        "plt.imshow(NN_input[5, :, :], cmap='viridis')\n",
        "#plt.title('output_test [' + str(test_id) + ']')\n",
        "plt.colorbar()\n",
        "plt.grid(None)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FFOVeBqx_yB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuSr41YKBvic"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(NN_input, NN_originals, test_size=0.1, random_state=1994) # We are taking 10% of the dataset for testing (works in pairs)\n",
        "print('X_train : ', X_train.shape)\n",
        "print('X_test : ', X_test.shape)\n",
        "print('Y_train : ', Y_train.shape)\n",
        "print('Y_test : ', Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNoSaJHXAzNc"
      },
      "source": [
        "output_train = Y_train # portion of the original images we used for training\n",
        "input_train = X_train # portion of the BPM images associated with Y_train\n",
        "output_test = Y_test # portion of the original images we used for testing\n",
        "input_test = X_test # portion of the BPM images associated with Y_test\n",
        "\n",
        "input_train= input_train.reshape(input_train.shape[0], 256, 256, 1)  # add an extra dimension to array\n",
        "output_train= output_train.reshape(output_train.shape[0], 256, 256, 1)\n",
        "input_test= input_test.reshape(input_test.shape[0], 256, 256, 1)\n",
        "output_test= output_test.reshape(output_test.shape[0], 256, 256, 1)\n",
        "\n",
        "\n",
        "\n",
        "print('* processing and shaping data')\n",
        "print()\n",
        "print('input_train : ', input_train.shape)\n",
        "print('output_train : ', output_train.shape)\n",
        "print('input_test : ', input_test.shape)\n",
        "print('output_test : ', output_test.shape)\n",
        "print()\n",
        "\n",
        "# plot example\n",
        "\n",
        "item_id = 15\n",
        "\n",
        "plt.imshow(input_train[item_id, :, :, 0], cmap='viridis')\n",
        "plt.title('input_train [' + str(item_id) + ']')\n",
        "plt.grid(None)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(output_train[item_id, :, :, 0], cmap='viridis')\n",
        "plt.title('output_train [' + str(item_id) + ']')\n",
        "plt.grid(None)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgB--wW0dGPU"
      },
      "source": [
        "### Define the network hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdlhlPRPdZck"
      },
      "source": [
        "optimizer_type = Adam(learning_rate=1e-5)  # optimisation algorithm: Adam \n",
        "loss = 'mean_squared_error'  # loss (cost) function to be minimised by the optimiser\n",
        "metrics = ['mean_absolute_error']  # network accuracy metric to be determined after each epoch\n",
        "validtrain_split_ratio = 0.2  # % of the seen dataset to be put aside for validation, rest is for training\n",
        "max_epochs = 150  # maxmimum number of epochs to be iterated\n",
        "batch_size = 20   # batch size for the training data set\n",
        "batch_shuffle = True   # shuffle the training data prior to batching before each epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6JHphuLcvb6"
      },
      "source": [
        "### Define the network architecture\n",
        "\n",
        "* using the Keras' *functional* model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVOQwMTkdrdb"
      },
      "source": [
        "input_shape = (256, 256, 1)\n",
        "inputs = Input(shape=input_shape)\n",
        "\n",
        "# encoder section\n",
        "\n",
        "down0 = Conv2D(8, (3, 3), padding='same')(inputs) # we have 8 kernels of size 3 x 3\n",
        "down0 = BatchNormalization()(down0) # thresholding \n",
        "down0 = Activation('relu')(down0) # pixel by pixel to discard negative values\n",
        "down0 = Conv2D(8, (3, 3), padding='same')(down0) # we add kernels and we convolve again; we have 8 kernels \n",
        "down0 = BatchNormalization()(down0)\n",
        "down0 = Activation('relu')(down0)\n",
        "down0_pool = MaxPooling2D((2, 2), strides=(2, 2))(down0) #  we check 2 x 2 matrices and take the max; we move 2 pixels in terms of columns and raws; this is the true downsampling step\n",
        "    \n",
        "down1 = Conv2D(16, (3, 3), padding='same')(down0_pool)\n",
        "down1 = BatchNormalization()(down1)\n",
        "down1 = Activation('relu')(down1)\n",
        "down1 = Conv2D(16, (3, 3), padding='same')(down1)\n",
        "down1 = BatchNormalization()(down1)\n",
        "down1 = Activation('relu')(down1)\n",
        "down1_pool = MaxPooling2D((2, 2), strides=(2, 2))(down1) \n",
        "\n",
        "down2 = Conv2D(32, (3, 3), padding='same')(down1_pool)\n",
        "down2 = BatchNormalization()(down2)\n",
        "down2 = Activation('relu')(down2)\n",
        "down2 = Conv2D(32, (3, 3), padding='same')(down2)\n",
        "down2 = BatchNormalization()(down2)\n",
        "down2 = Activation('relu')(down2)\n",
        "down2_pool = MaxPooling2D((2, 2), strides=(2, 2))(down2) \n",
        "\n",
        "down3 = Conv2D(64, (3, 3), padding='same')(down2_pool)\n",
        "down3 = BatchNormalization()(down3)\n",
        "down3 = Activation('relu')(down3)\n",
        "down3 = Conv2D(64, (3, 3), padding='same')(down3)\n",
        "down3 = BatchNormalization()(down3)\n",
        "down3 = Activation('relu')(down3)\n",
        "down3_pool = MaxPooling2D((2, 2), strides=(2, 2))(down3) \n",
        "\n",
        "down4 = Conv2D(128, (3, 3), padding='same')(down3_pool)\n",
        "down4 = BatchNormalization()(down4)\n",
        "down4 = Activation('relu')(down4)\n",
        "down4 = Conv2D(128, (3, 3), padding='same')(down4)\n",
        "down4 = BatchNormalization()(down4)\n",
        "down4 = Activation('relu')(down4)\n",
        "down4_pool = MaxPooling2D((2, 2), strides=(2, 2))(down4) \n",
        " \n",
        "# center section\n",
        "    \n",
        "center = Conv2D(128, (3, 3), padding='same')(down4_pool)\n",
        "center = BatchNormalization()(center)\n",
        "center = Activation('relu')(center)\n",
        "center = Conv2D(128, (3, 3), padding='same')(center)\n",
        "center = BatchNormalization()(center)\n",
        "center = Activation('relu')(center)\n",
        "    \n",
        "# decoder section WITHOUT (commented) skip connections to the encoder section\n",
        "\n",
        "up4 = UpSampling2D((2, 2))(center)\n",
        "#up2 = concatenate([down2, up2], axis=3)\n",
        "up4 = Conv2D(128, (3, 3), padding='same')(up4)\n",
        "up4 = BatchNormalization()(up4)\n",
        "up4 = Activation('relu')(up4)\n",
        "up4 = Conv2D(128, (3, 3), padding='same')(up4)\n",
        "up4 = BatchNormalization()(up4)\n",
        "up4 = Activation('relu')(up4)\n",
        "\n",
        "up3 = UpSampling2D((2, 2))(up4)\n",
        "#up2 = concatenate([down2, up2], axis=3)\n",
        "up3 = Conv2D(64, (3, 3), padding='same')(up3)\n",
        "up3 = BatchNormalization()(up3)\n",
        "up3 = Activation('relu')(up3)\n",
        "up3 = Conv2D(64, (3, 3), padding='same')(up3)\n",
        "up3 = BatchNormalization()(up3)\n",
        "up3 = Activation('relu')(up3)\n",
        "\n",
        "up2 = UpSampling2D((2, 2))(up3)\n",
        "#up2 = concatenate([down2, up2], axis=3)\n",
        "up2 = Conv2D(32, (3, 3), padding='same')(up2)\n",
        "up2 = BatchNormalization()(up2)\n",
        "up2 = Activation('relu')(up2)\n",
        "up2 = Conv2D(32, (3, 3), padding='same')(up2)\n",
        "up2 = BatchNormalization()(up2)\n",
        "up2 = Activation('relu')(up2)\n",
        "\n",
        "up1 = UpSampling2D((2, 2))(up2)\n",
        "#up1 = concatenate([down1, up1], axis=3)\n",
        "up1 = Conv2D(16, (3, 3), padding='same')(up1)\n",
        "up1 = BatchNormalization()(up1)\n",
        "up1 = Activation('relu')(up1)\n",
        "up1 = Conv2D(16, (3, 3), padding='same')(up1)\n",
        "up1 = BatchNormalization()(up1)\n",
        "up1 = Activation('relu')(up1)\n",
        "\n",
        "up0 = UpSampling2D((2, 2))(up1)\n",
        "#up0 = concatenate([down0, up0], axis=3)\n",
        "up0 = Conv2D(8, (3, 3), padding='same')(up0)\n",
        "up0 = BatchNormalization()(up0)\n",
        "up0 = Activation('relu')(up0)\n",
        "up0 = Conv2D(8, (3, 3), padding='same')(up0)\n",
        "up0 = BatchNormalization()(up0)\n",
        "up0 = Activation('relu')(up0)\n",
        "\n",
        "outputs = Conv2D(1, (1, 1), activation='relu')(up0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwllZ6zVd9QM"
      },
      "source": [
        "### Compile the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ngMDyUFeCDL"
      },
      "source": [
        "print()\n",
        "print('* Compiling the network model *')\n",
        "print()\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(optimizer=optimizer_type, loss=loss, metrics=metrics)\n",
        "\n",
        "# display a summary of the compiled neural network\n",
        "\n",
        "print(model.summary())  \n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvfyQk9LgaEz"
      },
      "source": [
        "### Train the neural network with the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmXxAsVZggoD"
      },
      "source": [
        "print('* Training the compiled network *')\n",
        "print()\n",
        "\n",
        "history = model.fit(input_train, output_train, \\\n",
        "                    batch_size=batch_size, \\\n",
        "                    epochs=max_epochs, \\\n",
        "                    validation_split=validtrain_split_ratio, \\\n",
        "                    shuffle=batch_shuffle)\n",
        "\n",
        "print()\n",
        "print('Training completed')\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT1FYewGwOo6"
      },
      "source": [
        "### Plot the training history of the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3NEJ2AywWZh"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "# model loss\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss : ' + loss)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='best')\n",
        "plt.show()\n",
        "#plt.savefig(\"MSE.png\")\n",
        "#files.download(\"MSE.png\") \n",
        "plt.close()\n",
        "\n",
        "# model accuracy metric\n",
        "\n",
        "plt.plot(np.array(history.history[metrics[0]]))\n",
        "plt.plot(np.array(history.history['val_' + metrics[0]]))\n",
        "plt.title('Model accuracy metric : ' + metrics[0])\n",
        "plt.ylabel('Accuracy metric')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='best')\n",
        "plt.show()\n",
        "#plt.savefig(\"MAE.png\")\n",
        "#files.download(\"MAE.png\") \n",
        "plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgUczSigiDFl"
      },
      "source": [
        "### Evaluate the trained network performance on the unseen test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKV_mSM76IK2"
      },
      "source": [
        "print('* Evaluating the performance of the trained network on the unseen test dataset *')\n",
        "print()\n",
        "\n",
        "evaluate_model = model.evaluate(x=input_test, y=output_test)\n",
        "loss_metric = evaluate_model [0]\n",
        "accuracy_metric = evaluate_model [1]\n",
        "\n",
        "print()\n",
        "print('Accuracy - ' + metrics[0] + ': %0.3f'%accuracy_metric)\n",
        "print('Loss - ' + loss + ': %0.3f'%loss_metric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI_9EivUxeko"
      },
      "source": [
        "### Predict the output of a given input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9Fa0l6KNV1A"
      },
      "source": [
        "print('* Predicting the output of a given input from test set *')\n",
        "print()\n",
        "\n",
        "test_id = 21\n",
        "\n",
        "input_predict = np.zeros(shape=(1, 256, 256, 1))  # create numpy array of required dimensions for network input\n",
        "\n",
        "input_predict[0, :, :, 0] = input_test[test_id, :, :, 0]  # reshaping test input image\n",
        "\n",
        "output_predict = model.predict(input_predict)\n",
        "\n",
        "\n",
        "print('test_id : ', test_id)\n",
        "print()\n",
        "\n",
        "# plot prediction example from test set\n",
        "\n",
        "plt.imshow(input_test[test_id, :, :, 0], cmap='viridis')\n",
        "plt.title('input_test [' + str(test_id) + ']')\n",
        "plt.grid(None)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()\n",
        "\n",
        "print()\n",
        "\n",
        "plt.imshow(output_predict[0, :, :, 0], cmap='viridis')\n",
        "plt.title('output_predict')\n",
        "plt.grid(None)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()\n",
        "\n",
        "print()\n",
        "\n",
        "plt.imshow(output_test[test_id, :, :, 0], cmap='viridis')\n",
        "plt.title('output_test [' + str(test_id) + ']')\n",
        "plt.grid(None)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I779hMd89eze"
      },
      "source": [
        "# Save some example reconstructions from the test set\n",
        "input_predict_all=np.zeros((1,256,256,13))\n",
        "output_predict_all=np.zeros((1,256,256,13))\n",
        "output_test_all=np.zeros((1,256,256,13))\n",
        "\n",
        "print('* Predicting the output of a given input from test set *')\n",
        "print()\n",
        "\n",
        "test_idss=[3, 8, 21, 42, 31, 66, 100, 94, 52, 77, 111, 69, 6] # 31 is the choice for the paper\n",
        "maee=np.zeros(shape=(1, 13))\n",
        "msee=np.zeros(shape=(1, 13))\n",
        "\n",
        "for ii in range(13):\n",
        "\n",
        "  test_id = test_idss[ii]\n",
        "\n",
        "  input_predict = np.zeros(shape=(1, 256, 256, 1))  # create numpy array of required dimensions for network input\n",
        "\n",
        "  input_predict[0, :, :, 0] = input_test[test_id, :, :, 0]  # reshaping test input image\n",
        "\n",
        "  output_predict = model.predict(input_predict)\n",
        "\n",
        "\n",
        "  print('test_id : ', test_id)\n",
        "  print()\n",
        "\n",
        "  # plot prediction example from test set\n",
        "\n",
        "  plt.imshow(input_predict[0, :, :, 0], cmap='viridis')\n",
        "  plt.title('input_test [' + str(test_id) + ']')\n",
        "  plt.grid(None)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.show()\n",
        "\n",
        "  print()\n",
        "\n",
        "  plt.imshow(output_predict[0, :, :, 0], cmap='viridis')\n",
        "  plt.title('output_predict')\n",
        "  plt.grid(None)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.show()\n",
        "\n",
        "  print()\n",
        "\n",
        "  plt.imshow(output_test[test_id, :, :, 0], cmap='viridis')\n",
        "  plt.title('output_test [' + str(test_id) + ']')\n",
        "  plt.grid(None)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.show()\n",
        "\n",
        "  # Individual MAE and MSE values for the given examples\n",
        "  maee[0,ii]=np.sum(np.abs(output_predict[0, :, :, 0]-output_test[test_id, :, :, 0]))/256/256\n",
        "  msee[0,ii]=np.sum((output_predict[0, :, :, 0]-output_test[test_id, :, :, 0])**2)/256/256\n",
        "\n",
        "  input_predict_all[0,:,:,ii]=input_predict[0, :, :, 0]\n",
        "  output_predict_all[0,:,:,ii]=output_predict[0, :, :, 0]\n",
        "  output_test_all[0,:,:,ii]=output_test[test_id, :, :, 0]\n",
        "\n",
        "\n",
        "sio.savemat('/content/drive/MyDrive/Giulia waveguides/Paper Rev/figs_30e-6.mat', {'input_predict_all':input_predict_all,'output_predict_all':output_predict_all,'output_test_all':output_test_all})\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}